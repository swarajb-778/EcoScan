# ğŸŒ± EcoScan - AI-Powered Waste Classification

![EcoScan Banner](docs/banner.png)

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![SvelteKit](https://img.shields.io/badge/SvelteKit-4A4A55?style=flat&logo=svelte&logoColor=FF3E00)](https://kit.svelte.dev/)
[![TypeScript](https://img.shields.io/badge/TypeScript-007ACC?style=flat&logo=typescript&logoColor=white)](https://www.typescriptlang.org/)
[![PWA](https://img.shields.io/badge/PWA-Ready-blueviolet)](https://developer.mozilla.org/en-US/docs/Web/Progressive_web_apps)

**Real-time waste classification using computer vision and voice recognition for better recycling.**

EcoScan is a Progressive Web Application that helps users properly sort waste by using AI-powered object detection, voice input, and image analysis. Built with SvelteKit and TypeScript, it runs entirely in the browser for instant responses and offline capability.

## âœ¨ Features

### ğŸ¥ Real-Time Detection
- **Live Camera Feed**: Point your camera at objects for instant classification
- **Bounding Box Overlay**: Visual indicators showing detected items
- **Multiple Object Detection**: Identify several items simultaneously
- **Performance Optimized**: Runs at 15-30 FPS on mobile devices

### ğŸ¤ Voice Input
- **Speech Recognition**: Say "plastic bottle" to get disposal instructions
- **Hands-Free Operation**: Perfect when your hands are full
- **Fallback Support**: Text input when voice isn't available
- **Multi-Language Ready**: Configurable language support

### ğŸ“¤ Image Upload
- **Drag & Drop**: Easy file upload interface
- **Static Analysis**: Detailed analysis of uploaded images
- **Batch Processing**: Handle multiple images at once
- **Format Support**: PNG, JPEG, WebP, and more

### â™»ï¸ Smart Classification
- **3-Category System**: Recycle, Compost, or Landfill
- **Disposal Instructions**: Detailed guidance for each item
- **Local Guidelines**: Customizable for regional rules
- **Confidence Scoring**: Transparency in AI decisions

### ğŸ“± Mobile-First Design
- **Progressive Web App**: Install directly from browser
- **Offline Capable**: Core features work without internet
- **Touch Optimized**: Haptic feedback and responsive design
- **Accessibility**: Screen reader support and keyboard navigation

## ğŸš€ Quick Start

### Prerequisites
- Node.js 18+ 
- Modern browser with camera support
- Python 3.8+ (for model setup)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/ecoscan.git
   cd ecoscan
   ```

2. **Run the setup script**
   ```bash
   chmod +x scripts/setup.sh
   ./scripts/setup.sh
   ```

3. **Start development server**
   ```bash
   npm run dev
   ```

4. **Open in browser**
   ```
   http://localhost:5173
   ```

### Manual Setup

If the setup script doesn't work:

1. **Install dependencies**
   ```bash
   npm install
   ```

2. **Download the YOLO model**
   ```bash
   python3 scripts/download-model.py
   ```

3. **Create environment file**
   ```bash
   cp .env.example .env
   ```

## ğŸ“ Project Structure

```
EcoScan/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ components/          # Svelte components
â”‚   â”‚   â”‚   â”œâ”€â”€ CameraView.svelte
â”‚   â”‚   â”‚   â”œâ”€â”€ VoiceInput.svelte
â”‚   â”‚   â”‚   â”œâ”€â”€ ImageUpload.svelte
â”‚   â”‚   â”‚   â”œâ”€â”€ DetectionDetails.svelte
â”‚   â”‚   â”‚   â”œâ”€â”€ ErrorBoundary.svelte
â”‚   â”‚   â”‚   â”œâ”€â”€ LoadingSpinner.svelte
â”‚   â”‚   â”‚   â””â”€â”€ TouchFeedback.svelte
â”‚   â”‚   â”œâ”€â”€ ml/                  # Machine learning
â”‚   â”‚   â”‚   â”œâ”€â”€ detector.ts      # Object detection
â”‚   â”‚   â”‚   â””â”€â”€ classifier.ts    # Waste classification
â”‚   â”‚   â”œâ”€â”€ stores/              # State management
â”‚   â”‚   â”‚   â”œâ”€â”€ appStore.ts
â”‚   â”‚   â”‚   â””â”€â”€ errorStore.ts
â”‚   â”‚   â”œâ”€â”€ utils/               # Utilities
â”‚   â”‚   â”‚   â”œâ”€â”€ performance.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ device.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ accessibility.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ build.ts
â”‚   â”‚   â”‚   â””â”€â”€ testing.ts
â”‚   â”‚   â”œâ”€â”€ config/              # Configuration
â”‚   â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚   â””â”€â”€ types/               # TypeScript types
â”‚   â”‚       â”œâ”€â”€ index.ts
â”‚   â”‚       â””â”€â”€ voice.d.ts
â”‚   â”œâ”€â”€ routes/                  # SvelteKit routes
â”‚   â”‚   â”œâ”€â”€ +page.svelte         # Camera view
â”‚   â”‚   â”œâ”€â”€ voice/
â”‚   â”‚   â”‚   â””â”€â”€ +page.svelte     # Voice input
â”‚   â”‚   â””â”€â”€ upload/
â”‚   â”‚       â””â”€â”€ +page.svelte     # Image upload
â”‚   â””â”€â”€ service-worker.ts        # PWA service worker
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ models/                  # ONNX models
â”‚   â”‚   â””â”€â”€ yolov8n.onnx
â”‚   â”œâ”€â”€ data/                    # Classification data
â”‚   â”‚   â””â”€â”€ wasteData.json
â”‚   â””â”€â”€ icons/                   # PWA icons
â”œâ”€â”€ scripts/                     # Build scripts
â”‚   â”œâ”€â”€ setup.sh
â”‚   â””â”€â”€ download-model.py
â””â”€â”€ docs/                        # Documentation
    â”œâ”€â”€ PRD_EcoScan_Detailed.md
    â””â”€â”€ Project_Breakdown_1Day.md
```

## âš™ï¸ Configuration

EcoScan uses environment variables for configuration. Copy `.env.example` to `.env` and customize:

```bash
# Feature toggles
VITE_ENABLE_VOICE_INPUT=true
VITE_ENABLE_CAMERA_DETECTION=true
VITE_ENABLE_IMAGE_UPLOAD=true

# Performance settings
VITE_MODEL_CONFIDENCE_THRESHOLD=0.5
VITE_MAX_DETECTIONS=20

# Development options
VITE_DEV_ENABLE_MOCK_MODEL=false
VITE_DEV_SHOW_PERFORMANCE_STATS=true
```

## ğŸ§ª Testing

### Running Tests
```bash
# Unit tests
npm run test

# E2E tests  
npm run test:e2e

# Visual regression tests
npm run test:visual
```

### Mock Mode
For development without a camera or model:

```typescript
import { testUtils } from '$lib/utils/testing';

// Enable mock mode
testUtils.enableMockMode();

// Use mock camera
const mockStream = createMockCameraStream();

// Use mock detector
const detector = new MockObjectDetector();
```

### Performance Testing
```typescript
import { PerformanceTester } from '$lib/utils/testing';

const tester = new PerformanceTester();
const end = tester.startMeasurement('inference');

// ... run inference ...

const duration = end();
console.log(tester.generateReport());
```

## ğŸ—ï¸ Building for Production

1. **Build the application**
   ```bash
   npm run build
   ```

2. **Preview production build**
   ```bash
   npm run preview
   ```

3. **Deploy to your platform**
   - Vercel: `vercel deploy`
   - Netlify: `netlify deploy --prod`
   - Static hosting: Copy `dist/` folder

### Build Optimization

The build process includes:
- **Code Splitting**: Automatic chunking for optimal loading
- **Tree Shaking**: Removes unused code
- **Asset Optimization**: Compressed images and fonts
- **Service Worker**: Caches resources for offline use
- **PWA Manifest**: Enables installation on mobile devices

## ğŸ”§ Development

### Adding New Waste Categories

1. **Update the data file** (`static/data/wasteData.json`):
   ```json
   {
     "glass_bottle": {
       "category": "recycle",
       "confidence": 0.9,
       "instructions": "Remove cap, rinse clean",
       "tips": ["Check for cracks", "Separate by color"]
     }
   }
   ```

2. **Add keyword mappings**:
   ```json
   {
     "keywords": {
       "wine bottle": ["glass_bottle"],
       "beer bottle": ["glass_bottle"]
     }
   }
   ```

### Custom Model Integration

Replace the YOLO model with your own:

1. **Export to ONNX format** (640x640 input size)
2. **Place in** `static/models/your-model.onnx`
3. **Update configuration**:
   ```typescript
   // src/lib/config/index.ts
   model: {
     modelPath: '/models/your-model.onnx',
     // ... other settings
   }
   ```

### Adding New Languages

1. **Update voice configuration**:
   ```typescript
   voice: {
     language: 'es-ES', // Spanish
     // ... other settings
   }
   ```

2. **Add translations** for UI text in component files

## ğŸ“Š Performance

### Benchmarks

| Device | Model Load | Inference | FPS | Memory |
|--------|------------|-----------|-----|--------|
| iPhone 13 | 2.3s | 45ms | 28 | 85MB |
| Pixel 6 | 1.8s | 38ms | 30 | 92MB |
| Desktop | 1.2s | 12ms | 60 | 120MB |

### Optimization Tips

- **Model Size**: YOLOv8n is optimized for speed over accuracy
- **Input Resolution**: Lower resolution = faster inference
- **Confidence Threshold**: Higher threshold = fewer false positives
- **Device Memory**: Monitor usage with performance tools

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

### Development Workflow

1. **Fork the repository**
2. **Create a feature branch**: `git checkout -b feature/amazing-feature`
3. **Make your changes**
4. **Add tests** for new functionality
5. **Commit your changes**: `git commit -m 'Add amazing feature'`
6. **Push to the branch**: `git push origin feature/amazing-feature`
7. **Open a Pull Request**

### Code Style

- **TypeScript**: Strict mode enabled
- **Prettier**: Auto-formatting on save
- **ESLint**: Linting rules enforced
- **Svelte**: Component-based architecture

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **YOLOv8**: Object detection model by [Ultralytics](https://ultralytics.com/)
- **ONNX Runtime**: Cross-platform ML inference by [Microsoft](https://onnxruntime.ai/)
- **SvelteKit**: Web framework by the [Svelte team](https://svelte.dev/)
- **Tailwind CSS**: Utility-first CSS framework
- **DaisyUI**: Tailwind CSS component library

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/yourusername/ecoscan/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/ecoscan/discussions)
- **Email**: support@ecoscan.app

---

**Made with ğŸ’š for a cleaner planet**

*Help us improve waste sorting, one scan at a time.*
